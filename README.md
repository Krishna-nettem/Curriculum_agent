<div align="center">
ğŸ“ AI Curriculum Generator
Intelligent Course Design Powered by Multi-Agent AI
[![Python](https://img.shields.io/badge/Python-3.12+-t-1.52testow.svg

Features - Demo - Installation - Usage - Architecture - API

</div>
ğŸŒŸ Overview
AI Curriculum Generator is a production-ready, multi-agent system that autonomously researches any topic and generates comprehensive, structured curricula. Built with LangGraph for orchestration, it combines advanced web search, intelligent content extraction, and LLM-powered generation to create professional course outlines in seconds.

Why This Project?
ğŸ¯ Autonomous Research: No manual content curation needed

ğŸ§  Multi-Agent Architecture: Specialized agents for research and curriculum design

ğŸ” High-Quality Sources: Tavily AI ensures academically sound content

ğŸ“Š State Management: LangGraph provides robust workflow orchestration

ğŸ¨ Professional Output: Export to beautifully formatted PDFs

âœ¨ Features
Core Capabilities
Feature	Description
ğŸ” Intelligent Search	Tavily AI API with advanced search depth for quality sources
ğŸ•·ï¸ Smart Scraping	Crawl4AI with content filtering (removes navigation, ads, footers)
ğŸ¤– Dual LLM Support	Gemini (primary) + Ollama (fallback) for reliability
ğŸ“ Structured Output	Markdown-formatted curricula with modules, objectives, projects
ğŸ“¥ PDF Export	WeasyPrint-generated professional documents
ğŸ’¾ Session Persistence	Streamlit state management prevents data loss
ğŸ“Š Progress Tracking	Real-time status updates during generation
ğŸ”„ Error Handling	Graceful fallbacks and comprehensive logging
ğŸ¬ Demo
bash
# Input
Topic: "Generative AI for Beginners"

# Output
âœ… 6-8 high-quality sources researched
âœ… 15,000+ characters of curated content
âœ… Professional curriculum with 6 modules
âœ… Learning objectives, projects, and resources
âœ… Downloadable PDF in <60 seconds
ğŸ—ï¸ Architecture
System Flow
text
User Input (Topic)
     â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  LangGraph Entry   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
     â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Research Agent    â”‚
â”‚  â€¢ Tavily Search   â”‚
â”‚  â€¢ URL Discovery   â”‚
â”‚  â€¢ Crawl4AI Scrape â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
     â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Quality Gate      â”‚
â”‚  (500+ char check) â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
     â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Curriculum Agent   â”‚
â”‚  â€¢ Gemini LLM      â”‚
â”‚  â€¢ Prompt Template â”‚
â”‚  â€¢ Markdown Output â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
     â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Streamlit UI     â”‚
â”‚  â€¢ Display         â”‚
â”‚  â€¢ PDF Export      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
Tech Stack
Frontend: Streamlit 1.52+
AI Framework: LangGraph, LangChain
LLMs: Google Gemini Flash, Ollama (llama3.2:3b)
Search: Tavily AI (advanced depth)
Web Scraping: Crawl4AI (async, filtered)
PDF Generation: WeasyPrint + Markdown
State: Pydantic models with session persistence

ğŸš€ Installation
Prerequisites
Python 3.12+

Ollama (optional, for local LLM fallback)

API Keys: Gemini, Tavily

Quick Start
bash
# Clone repository
git clone https://github.com/YOUR_USERNAME/curriculum-agent.git
cd curriculum-agent

# Create virtual environment
python3 -m venv langgraph-env
source langgraph-env/bin/activate  # Windows: langgraph-env\Scripts\activate

# Install dependencies
pip install -r requirements.txt

# Configure environment
cp .env.example .env
nano .env  # Add your API keys
Environment Variables
text
# Required
GEMINI_API_KEY=your_gemini_api_key_here
TAVILY_API_KEY=your_tavily_api_key_here

# Optional (for Ollama fallback)
OLLAMA_MODEL=llama3.2:3b
Ollama Setup (Optional)
bash
# Install Ollama
curl -fsSL https://ollama.com/install.sh | sh

# Pull model
ollama pull llama3.2:3b

# Verify
ollama run llama3.2:3b "test"
ğŸ’» Usage
Run the Application
bash
streamlit run app.py
Command Line Options
bash
# Custom port
streamlit run app.py --server.port 8080

# Production mode
streamlit run app.py --server.headless true
Example Workflow
Enter Topic: "Machine Learning Fundamentals"

Wait: Research agent searches + scrapes (30-45s)

Generate: LLM creates curriculum (15-30s)

Download: Export as PDF with one click

ğŸ“‚ Project Structure
text
curriculum-agent/
â”œâ”€â”€ app.py                 # Streamlit UI with session state
â”œâ”€â”€ graph.py              # LangGraph workflow definition
â”œâ”€â”€ agents.py             # Research & curriculum agents
â”‚   â”œâ”€â”€ tavily_search()   # Web search with Tavily
â”‚   â”œâ”€â”€ crawl_urls_full() # Content extraction
â”‚   â””â”€â”€ curriculum_agent() # LLM generation
â”œâ”€â”€ llm.py                # Gemini + Ollama integrations
â”œâ”€â”€ prompts.py            # Curriculum generation prompts
â”œâ”€â”€ state.py              # Pydantic state models
â”œâ”€â”€ logger.py             # Structured JSON logging
â”œâ”€â”€ .env                  # API keys (gitignored)
â”œâ”€â”€ .gitignore            # Exclusions
â”œâ”€â”€ requirements.txt      # Python dependencies
â””â”€â”€ README.md            # This file
ğŸ”§ API Reference
Research Agent
python
def research_agent(topic: str) -> dict:
    """
    Searches web and extracts content for curriculum generation.
    
    Args:
        topic: Course topic (e.g., "React.js")
    
    Returns:
        {
            "summary": str,
            "notes": List[{"url": str, "text": str}],
            "images": List[str],
            "sources": List[str]
        }
    """
Curriculum Agent
python
def curriculum_agent(topic: str, difficulty: str, research_data: dict) -> dict:
    """
    Generates structured curriculum from research data.
    
    Args:
        topic: Course topic
        difficulty: "Beginner" | "Intermediate" | "Advanced"
        research_data: Output from research_agent()
    
    Returns:
        {
            "text": str,  # Markdown curriculum
            "source": "gemini" | "ollama" | "fallback",
            "sources": List[str]
        }
    """
ğŸ› Troubleshooting
Ollama Timeout
Error: ReadTimeout: Read timed out. (read timeout=120)

Solution:

python
# In llm.py, increase timeout
timeout=600  # 10 minutes

# Or use faster model
ollama pull llama3.2:3b  # 3B is 3-4x faster than 8B
Crawl4AI Content Issues
Problem: Too much navigation/junk scraped

Solution: Already configured in agents.py with:

excluded_tags=['nav', 'footer', 'header', 'aside']

css_selector="article, main, .content"

Custom text cleaning filters

PDF Generation Fails
Error: WeasyPrint installation issues

Solution:

bash
# Ubuntu/Debian
sudo apt-get install python3-dev python3-pip python3-cffi libcairo2 libpango-1.0-0

# macOS
brew install cairo pango gdk-pixbuf libffi
ğŸ›£ï¸ Roadmap
 Multi-language support (Spanish, French, Hindi)

 Custom difficulty levels (user-adjustable)

 Video integration (YouTube API for resource links)

 Collaborative editing (multi-user curriculum refinement)

 Vector search (semantic similarity for better sources)

 Analytics dashboard (track generation metrics)

ğŸ¤ Contributing
Contributions are welcome! Please follow these steps:

Fork the repository

Create feature branch (git checkout -b feature/AmazingFeature)

Commit changes (git commit -m 'Add AmazingFeature')

Push to branch (git push origin feature/AmazingFeature)

Open Pull Request

Development Setup
bash
# Install dev dependencies
pip install -r requirements-dev.txt

# Run tests
pytest tests/

# Format code
black .
flake8 .
ğŸ“ License
This project is licensed under the MIT License - see LICENSE file for details.

ğŸ™ Acknowledgments
LangGraph - Agent orchestration framework

Tavily AI - Search API for AI applications

Crawl4AI - LLM-friendly web scraping

Streamlit - Rapid web app framework
